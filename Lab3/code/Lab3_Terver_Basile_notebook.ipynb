{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> [Basile Terver]\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import inspect\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid,dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid,nhead,dim_feedforward=nhid,dropout=dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)#fill me\n",
        "        output = self.transformer_encoder(src, src_mask) #fill me\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(in_features=nhid,out_features=nclasses)#fill me\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout) #fill me\n",
        "        self.classifier = ClassificationHead(nhid, nclasses) #fill me\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src,src_mask) #fill me\n",
        "        # classifier model\n",
        "        output =self.classifier(x) #fill me\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhb2gkUhJMR0",
        "outputId": "7c7f36bb-d16d-4836-c37d-fdd8b16117cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of parameters of base.encoder.weight is 20000\n",
            "number of parameters of base.transformer_encoder.layers.0.self_attn.in_proj_weight is 120000\n",
            "number of parameters of base.transformer_encoder.layers.0.self_attn.in_proj_bias is 600\n",
            "number of parameters of base.transformer_encoder.layers.0.self_attn.out_proj.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.0.self_attn.out_proj.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.0.linear1.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.0.linear1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.0.linear2.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.0.linear2.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.0.norm1.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.0.norm1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.0.norm2.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.0.norm2.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.1.self_attn.in_proj_weight is 120000\n",
            "number of parameters of base.transformer_encoder.layers.1.self_attn.in_proj_bias is 600\n",
            "number of parameters of base.transformer_encoder.layers.1.self_attn.out_proj.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.1.self_attn.out_proj.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.1.linear1.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.1.linear1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.1.linear2.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.1.linear2.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.1.norm1.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.1.norm1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.1.norm2.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.1.norm2.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.2.self_attn.in_proj_weight is 120000\n",
            "number of parameters of base.transformer_encoder.layers.2.self_attn.in_proj_bias is 600\n",
            "number of parameters of base.transformer_encoder.layers.2.self_attn.out_proj.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.2.self_attn.out_proj.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.2.linear1.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.2.linear1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.2.linear2.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.2.linear2.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.2.norm1.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.2.norm1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.2.norm2.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.2.norm2.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.3.self_attn.in_proj_weight is 120000\n",
            "number of parameters of base.transformer_encoder.layers.3.self_attn.in_proj_bias is 600\n",
            "number of parameters of base.transformer_encoder.layers.3.self_attn.out_proj.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.3.self_attn.out_proj.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.3.linear1.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.3.linear1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.3.linear2.weight is 40000\n",
            "number of parameters of base.transformer_encoder.layers.3.linear2.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.3.norm1.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.3.norm1.bias is 200\n",
            "number of parameters of base.transformer_encoder.layers.3.norm2.weight is 200\n",
            "number of parameters of base.transformer_encoder.layers.3.norm2.bias is 200\n",
            "number of parameters of classifier.decoder.weight is 20000\n",
            "number of parameters of classifier.decoder.bias is 100\n",
            "base model trainable weights= 988000\n",
            "classifier trainable weights= 20100\n",
            "torch.Size([1, 6, 100])\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print('number of parameters of',name,'is' ,param.numel())\n",
        "\n",
        "print('base model trainable weights=',count_parameters(model.base))\n",
        "print('classifier trainable weights=',count_parameters(model.classifier))\n",
        "\n",
        "#print(inspect.getmembers(model))\n",
        "\n",
        "print(out.shape) # is it the right shape?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qjd26ghWuff",
        "outputId": "8116055a-c0b4-4594-cb2b-f4c12de5ec11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 15:13:33--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt’\n",
            "\n",
            "dict.txt            100%[===================>] 564.05K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-30 15:13:33 (15.2 MB/s) - ‘dict.txt’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFdH_-JeFbGA",
        "outputId": "cb9e3415-8ef6-40e7-bedf-18faf4fde034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] = idx+4 #fill me\n",
        "\n",
        "ind2token = {} #fill me\n",
        "for token,ind in token2ind.items():\n",
        "    ind2token[ind]=token\n",
        "#ind2token = {v: k for k, v in token2ind.items()}\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence =[self.token2ind['<sos>']]+ [self.token2ind[token] if token in token2ind.keys() else self.token2ind['<oov>'] for token in sequence ]#fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
        "        #source_sequence = [token2ind.get('<sos>')] + [token2ind.get(token) if token2ind.get(token) != None else 3 for token in sequence]\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1]#fill me\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1] #fill me\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output,target) #fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        #fill me step 4\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgf6BDB9jUr6",
        "outputId": "48c6e12d-f890-4e29-9c89-f12e132f168d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ntokens= 50001\n",
            "base model trainable weights= 10968200\n",
            "classifier trainable weights= 10050201\n"
          ]
        }
      ],
      "source": [
        "ntokens = len(token2ind) #fill me # the size of vocabulary\n",
        "print('ntokens=',ntokens)\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "\n",
        "print('base model trainable weights=',count_parameters(model.base))\n",
        "print('classifier trainable weights=',count_parameters(model.classifier))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G8lh9KkaJ2t",
        "outputId": "307575fe-a9eb-4af9-a6b4-ea23fcfdb525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------+--------------------------+\n",
            "|                            Module                           | Number trainable weights |\n",
            "+-------------------------------------------------------------+--------------------------+\n",
            "|                     base.encoder.weight                     |         10000200         |\n",
            "|  base.transformer_encoder.layers.0.self_attn.in_proj_weight |          120000          |\n",
            "|   base.transformer_encoder.layers.0.self_attn.in_proj_bias  |           600            |\n",
            "| base.transformer_encoder.layers.0.self_attn.out_proj.weight |          40000           |\n",
            "|  base.transformer_encoder.layers.0.self_attn.out_proj.bias  |           200            |\n",
            "|       base.transformer_encoder.layers.0.linear1.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.0.linear1.bias       |           200            |\n",
            "|       base.transformer_encoder.layers.0.linear2.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.0.linear2.bias       |           200            |\n",
            "|        base.transformer_encoder.layers.0.norm1.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.0.norm1.bias        |           200            |\n",
            "|        base.transformer_encoder.layers.0.norm2.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.0.norm2.bias        |           200            |\n",
            "|  base.transformer_encoder.layers.1.self_attn.in_proj_weight |          120000          |\n",
            "|   base.transformer_encoder.layers.1.self_attn.in_proj_bias  |           600            |\n",
            "| base.transformer_encoder.layers.1.self_attn.out_proj.weight |          40000           |\n",
            "|  base.transformer_encoder.layers.1.self_attn.out_proj.bias  |           200            |\n",
            "|       base.transformer_encoder.layers.1.linear1.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.1.linear1.bias       |           200            |\n",
            "|       base.transformer_encoder.layers.1.linear2.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.1.linear2.bias       |           200            |\n",
            "|        base.transformer_encoder.layers.1.norm1.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.1.norm1.bias        |           200            |\n",
            "|        base.transformer_encoder.layers.1.norm2.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.1.norm2.bias        |           200            |\n",
            "|  base.transformer_encoder.layers.2.self_attn.in_proj_weight |          120000          |\n",
            "|   base.transformer_encoder.layers.2.self_attn.in_proj_bias  |           600            |\n",
            "| base.transformer_encoder.layers.2.self_attn.out_proj.weight |          40000           |\n",
            "|  base.transformer_encoder.layers.2.self_attn.out_proj.bias  |           200            |\n",
            "|       base.transformer_encoder.layers.2.linear1.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.2.linear1.bias       |           200            |\n",
            "|       base.transformer_encoder.layers.2.linear2.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.2.linear2.bias       |           200            |\n",
            "|        base.transformer_encoder.layers.2.norm1.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.2.norm1.bias        |           200            |\n",
            "|        base.transformer_encoder.layers.2.norm2.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.2.norm2.bias        |           200            |\n",
            "|  base.transformer_encoder.layers.3.self_attn.in_proj_weight |          120000          |\n",
            "|   base.transformer_encoder.layers.3.self_attn.in_proj_bias  |           600            |\n",
            "| base.transformer_encoder.layers.3.self_attn.out_proj.weight |          40000           |\n",
            "|  base.transformer_encoder.layers.3.self_attn.out_proj.bias  |           200            |\n",
            "|       base.transformer_encoder.layers.3.linear1.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.3.linear1.bias       |           200            |\n",
            "|       base.transformer_encoder.layers.3.linear2.weight      |          40000           |\n",
            "|        base.transformer_encoder.layers.3.linear2.bias       |           200            |\n",
            "|        base.transformer_encoder.layers.3.norm1.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.3.norm1.bias        |           200            |\n",
            "|        base.transformer_encoder.layers.3.norm2.weight       |           200            |\n",
            "|         base.transformer_encoder.layers.3.norm2.bias        |           200            |\n",
            "|                  classifier.decoder.weight                  |         10000200         |\n",
            "|                   classifier.decoder.bias                   |          50001           |\n",
            "+-------------------------------------------------------------+--------------------------+\n",
            "Total number trainable params: 21018401\n"
          ]
        }
      ],
      "source": [
        "import sympy\n",
        "from sympy import symbols, Eq, solve, sympify\n",
        "from IPython.display import display, Markdown\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "#Done with the help of ChatGPT\n",
        "def parameters_table(model):\n",
        "  table=PrettyTable([\"Module\",\"Number trainable weights\"])\n",
        "  total_nb_params=0\n",
        "  for name,param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "      nb_params=param.numel()\n",
        "      table.add_row([name,nb_params])\n",
        "      total_nb_params+=nb_params\n",
        "  print(table)\n",
        "  print(f\"Total number trainable params:\",total_nb_params)\n",
        "\n",
        "parameters_table(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization parameters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwh3n9xZQy4e",
        "outputId": "e41515f3-19cd-4727-b07d-e800c620eeeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 15:13:34--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-10-30 15:13:34 (138 MB/s) - ‘pretraining_subset.txt’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m11g4ScjZaR",
        "outputId": "ab008e39-40d4-4ce9-9321-f987bdb704f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.30129 | ppl 1482.206\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.47896 | ppl  651.290\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.21225 | ppl  498.821\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.04618 | ppl  422.497\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.92541 | ppl  374.430\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.82820 | ppl  339.745\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.52108 | ppl  249.904\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.48774 | ppl  241.709\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.44714 | ppl  232.094\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.41258 | ppl  224.210\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.37499 | ppl  215.938\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.36866 | ppl  214.574\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task='language_modeling', # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BcBC6FSkMH3",
        "outputId": "d3a20e3b-30b1-4870-9255-f2859504b96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 15:18:26--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   349MB/s    in 0.2s    \n",
            "\n",
            "2023-10-30 15:18:26 (349 MB/s) - ‘pretrained_model_4layers.pt’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBRRVsWqlIoQ",
        "outputId": "5e7655f9-3d02-4bbb-e077-cc5e462949cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "--2023-10-30 15:18:32--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-30 15:18:33 (24.7 MB/s) - ‘sentencepiece.french.model’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    #print('sent_pieces=', sent_pieces)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    #print('out shape=',out.shape)\n",
        "    next_token_ind = out.argmax(-1) #fill me\n",
        "    #print('next_token_ind argmax',next_token_ind)\n",
        "    next_token_ind=next_token_ind[-1,0]\n",
        "    #print('last next_token_ind=',next_token_ind)\n",
        "    next_token_ind=int(next_token_ind)\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    # to be implemented\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    completed_sent = sent\n",
        "    completed_sent_pieces = sent_pieces\n",
        "    while len(completed_sent_pieces)<max_len:\n",
        "      next_token_ind=infer_next_token(completed_sent)[0]\n",
        "      #print('next_token_ind=',next_token_ind)\n",
        "      next_token=ind2token.get(next_token_ind)\n",
        "      #print('next_token=',next_token)\n",
        "      completed_sent_pieces.append(next_token)\n",
        "      completed_sent = s.decode_pieces(completed_sent_pieces)\n",
        "      if next_token_ind==2:\n",
        "        break\n",
        "    return completed_sent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "f83Nn5nSly4v",
        "outputId": "4f1c5392-5a1d-419f-e912-bebe24904b1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques.<eos>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pDscInaqlTPo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K1BZsblmEmx",
        "outputId": "8566f42d-606f-4c57-bc7a-56d94fd0b4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 15:18:33--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm’\n",
            "\n",
            "train.review.spm    100%[===================>]   1.43M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-10-30 15:18:33 (33.3 MB/s) - ‘train.review.spm’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-30 15:18:33--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label’\n",
            "\n",
            "train.label         100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-30 15:18:33 (53.3 MB/s) - ‘train.label’ saved [3200/3200]\n",
            "\n",
            "--2023-10-30 15:18:33--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm’\n",
            "\n",
            "test.review.spm     100%[===================>]   1.78M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-30 15:18:34 (38.1 MB/s) - ‘test.review.spm’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-30 15:18:34--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label’\n",
            "\n",
            "test.label          100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-30 15:18:34 (72.6 MB/s) - ‘test.label’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    #to be implemented\n",
        "    N=len(data_loader.dataset)\n",
        "    #print('N=',N)\n",
        "    batch_size=data_loader.batch_size\n",
        "    #print('batch_size=',batch_size)\n",
        "    outputs=torch.zeros(N)#.to(device)\n",
        "    targets=torch.zeros(N)#.to(device)\n",
        "    for idx, data in enumerate(data_loader):\n",
        "      src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "        device)\n",
        "      input = data[0].to(device)\n",
        "      output = model(input, src_mask)\n",
        "      #if data_loader.task == 'classification':\n",
        "      output = output[-1]\n",
        "      #print('output[-1] shape=',output.shape)\n",
        "      #output = output.view(-1, output.shape[-1])\n",
        "      #print('output reshaped shape=',output.shape)\n",
        "      #take most probable of the two classes\n",
        "      #print('output.argmax(axis=1) shape=',output.argmax(axis=1).shape)\n",
        "      #print('idx=',idx)\n",
        "      outputs[idx*batch_size: (idx+1)*batch_size] = output.argmax(axis=1)\n",
        "      #print('output post argmax shape=',output.shape)\n",
        "      targets[idx*batch_size: (idx+1)*batch_size] = data[1]\n",
        "      #print('target shape=',target.shape)\n",
        "      #target = target.to(device)\n",
        "\n",
        "\n",
        "    #print('targets shape=',targets.shape)\n",
        "    #print('outputs shape=',outputs.shape)\n",
        "    return torch.sum(targets==outputs)/N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-xclMCpnVpw",
        "outputId": "167e843b-b48e-4d9c-b517-63a7fe1dce4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.75491 | ppl    2.127\n",
            "| epoch   1 |   100/  200 steps | loss 0.74181 | ppl    2.100\n",
            "| epoch   1 |   150/  200 steps | loss 0.73361 | ppl    2.083\n",
            "| epoch   2 |    50/  200 steps | loss 0.64499 | ppl    1.906\n",
            "| epoch   2 |   100/  200 steps | loss 0.63780 | ppl    1.892\n",
            "| epoch   2 |   150/  200 steps | loss 0.59072 | ppl    1.805\n",
            "| epoch   3 |    50/  200 steps | loss 0.46394 | ppl    1.590\n",
            "| epoch   3 |   100/  200 steps | loss 0.36906 | ppl    1.446\n",
            "| epoch   3 |   150/  200 steps | loss 0.40134 | ppl    1.494\n",
            "| epoch   4 |    50/  200 steps | loss 0.23960 | ppl    1.271\n",
            "| epoch   4 |   100/  200 steps | loss 0.12400 | ppl    1.132\n",
            "| epoch   4 |   150/  200 steps | loss 0.11196 | ppl    1.118\n",
            "| epoch   5 |    50/  200 steps | loss 0.01505 | ppl    1.015\n",
            "| epoch   5 |   100/  200 steps | loss 0.03836 | ppl    1.039\n",
            "| epoch   5 |   150/  200 steps | loss 0.04676 | ppl    1.048\n",
            "| epoch   6 |    50/  200 steps | loss 0.00330 | ppl    1.003\n",
            "| epoch   6 |   100/  200 steps | loss 0.03011 | ppl    1.031\n",
            "| epoch   6 |   150/  200 steps | loss 0.00754 | ppl    1.008\n",
            "| epoch   7 |    50/  200 steps | loss 0.00162 | ppl    1.002\n",
            "| epoch   7 |   100/  200 steps | loss 0.00020 | ppl    1.000\n",
            "| epoch   7 |   150/  200 steps | loss 0.00006 | ppl    1.000\n",
            "| epoch   8 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00084 | ppl    1.001\n",
            "| epoch   8 |   150/  200 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00735 | ppl    1.007\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.76755 | ppl    2.154\n",
            "| epoch   1 |   100/  200 steps | loss 0.64424 | ppl    1.905\n",
            "| epoch   1 |   150/  200 steps | loss 0.62059 | ppl    1.860\n",
            "| epoch   2 |    50/  200 steps | loss 0.49921 | ppl    1.647\n",
            "| epoch   2 |   100/  200 steps | loss 0.43840 | ppl    1.550\n",
            "| epoch   2 |   150/  200 steps | loss 0.46888 | ppl    1.598\n",
            "| epoch   3 |    50/  200 steps | loss 0.32493 | ppl    1.384\n",
            "| epoch   3 |   100/  200 steps | loss 0.37077 | ppl    1.449\n",
            "| epoch   3 |   150/  200 steps | loss 0.35456 | ppl    1.426\n",
            "| epoch   4 |    50/  200 steps | loss 0.26636 | ppl    1.305\n",
            "| epoch   4 |   100/  200 steps | loss 0.25133 | ppl    1.286\n",
            "| epoch   4 |   150/  200 steps | loss 0.25488 | ppl    1.290\n",
            "| epoch   5 |    50/  200 steps | loss 0.20139 | ppl    1.223\n",
            "| epoch   5 |   100/  200 steps | loss 0.11691 | ppl    1.124\n",
            "| epoch   5 |   150/  200 steps | loss 0.22970 | ppl    1.258\n",
            "| epoch   6 |    50/  200 steps | loss 0.06643 | ppl    1.069\n",
            "| epoch   6 |   100/  200 steps | loss 0.07885 | ppl    1.082\n",
            "| epoch   6 |   150/  200 steps | loss 0.16109 | ppl    1.175\n",
            "| epoch   7 |    50/  200 steps | loss 0.00495 | ppl    1.005\n",
            "| epoch   7 |   100/  200 steps | loss 0.03778 | ppl    1.039\n",
            "| epoch   7 |   150/  200 steps | loss 0.01818 | ppl    1.018\n",
            "| epoch   8 |    50/  200 steps | loss 0.02270 | ppl    1.023\n",
            "| epoch   8 |   100/  200 steps | loss 0.02188 | ppl    1.022\n",
            "| epoch   8 |   150/  200 steps | loss 0.00349 | ppl    1.004\n",
            "| epoch   9 |    50/  200 steps | loss 0.01280 | ppl    1.013\n",
            "| epoch   9 |   100/  200 steps | loss 0.00974 | ppl    1.010\n",
            "| epoch   9 |   150/  200 steps | loss 0.02291 | ppl    1.023\n",
            "| epoch  10 |    50/  200 steps | loss 0.00727 | ppl    1.007\n",
            "| epoch  10 |   100/  200 steps | loss 0.00151 | ppl    1.002\n",
            "| epoch  10 |   150/  200 steps | loss 0.00030 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00288 | ppl    1.003\n",
            "| epoch  11 |   100/  200 steps | loss 0.00016 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00597 | ppl    1.006\n",
            "| epoch  12 |    50/  200 steps | loss 0.00063 | ppl    1.001\n",
            "| epoch  12 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00060 | ppl    1.001\n",
            "| epoch  13 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.01992 | ppl    1.020\n",
            "| epoch  15 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00251 | ppl    1.003\n",
            "| epoch  15 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "RCpBIdTHojm6",
        "outputId": "8e536555-aa3f-456c-eb6b-52d077fdb344"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = list(range(1, len(from_scratch_valid_acc) + 1))\n",
        "\n",
        "plt.plot(epochs, from_scratch_valid_acc, label='From Scratch Valid Accuracy')\n",
        "plt.plot(epochs, pretrained_valid_acc, label='Pretrained Valid Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Comparison of Valid Accuracies')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}